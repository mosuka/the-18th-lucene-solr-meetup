morphlines : [
  {
    # Name used to identify a morphline. E.g. used if there are multiple
    # morphlines in a morphline config file
    id : httpd_logs

    # Import all morphline commands in these java packages and their
    # subpackages. Other commands that may be present on the classpath are
    # not visible to this morphline.
    importCommands : ["org.kitesdk.**", "org.apache.solr.**"]

    commands : [
      {
        # Parse input attachment and emit a record for each input line
        readLine {
          charset : UTF-8
        }
      }

      {
        grok {
          # Consume the output record of the previous command and pipe another
          # record downstream.
          #
          # A grok-dictionary is a config file that contains prefabricated
          # regular expressions that can be referred to by name. grok patterns
          # specify such a regex name, plus an optional output field name.
          # The syntax is %{REGEX_NAME:OUTPUT_FIELD_NAME}
          # The input line is expected in the "message" input field.
          dictionaryFiles : [./flume/apache-flume-1.7.0-SNAPSHOT-bin/resources/grok-dictionaries]
          expressions : {
            message : """%{COMBINEDAPACHELOG}"""
          }
        }
      }

      # Set values
      {
        setValues {
          event_timestamp : "@{timestamp}"
        }
      }

      {
        convertTimestamp {
          field : event_timestamp
          inputFormats : ["dd/MMM/yyyy:HH:mm:ss Z"]
          inputTimezone : Asia/Tokyo
          outputFormat : "yyyy-MM-dd'T'HH:mm:ss.SSS'Z'"
          outputTimezone : UTC
        }
      }

      {
        geoIP {
          inputField : clientip
          database : "./flume/apache-flume-1.7.0-SNAPSHOT-bin/resources/geoip/GeoLite2-City.mmdb"
        }
      }

      {
        extractJsonPaths {
          flatten : true
          paths : {
            country_iso_code : /country/iso_code
            location_latitude_longitude : /location/latitude_longitude
          }
        }
      }

      # remove temporary work fields.
      {
        setValues {
          _attachment_body : []
        }
      }

      # Consume the output record of the previous command, transform it
      # and pipe the record downstream.
      #
      # This command deletes record fields that are unknown to Solr
      # schema.xml. Recall that Solr throws an exception on any attempt to
      # load a document that contains a field that isn't specified in
      # schema.xml.
      #{
      #  sanitizeUnknownSolrFields {
      #    # Location from which to fetch Solr schema
      #    solrLocator : {
      #      solrUrl : "http://localhost:8983/solr/collection1/"  # Solr URL
      #      # zkHost : "127.0.0.1:2181/solr"                     # ZooKeeper ensemble
      #      # collection : collection1                           # Name of solr collection
      #    }
      #  }
      #}

      # log the record at INFO level to SLF4J
      { logInfo { format : "output record: {}", args : ["@{}"] } }

      # load the record into a Solr server or MapReduce Reducer
      {
        loadSolr {
          solrLocator : {
            batchSize : 1
            # solrUrl : "http://localhost:8983/solr/access_log"
            zkHost : "127.0.0.1:2181/solr"
            collection : access_log
          }
        }
      }
    ]
  }
]
